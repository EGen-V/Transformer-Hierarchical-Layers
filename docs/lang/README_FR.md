<!---
Copyright 2026 EGen Team. All rights reserved.

Licensed under the MIT License.
-->

<div align="center">
    <img src="../../docs/assets/banner.png" alt="THL Banner" width="100%"/>
</div>
<br>

<p align="center">
    <img src="https://img.shields.io/badge/python-3.8+-blue.svg" alt="Python Version">
    <img src="https://img.shields.io/badge/license-MIT-green.svg" alt="License">
    <img src="https://img.shields.io/badge/vram-4GB-orange.svg" alt="VRAM Optimized">
    <a href="https://github.com/EGen-V/Transformer-Hierarchical-Layers/actions"><img src="https://github.com/EGen-V/Transformer-Hierarchical-Layers/workflows/Tests/badge.svg" alt="Tests"></a>
</p>

<h1 align="center">ü§ó THL: Transformer Hierarchical Layers</h1>

<p align="center">
    <a href="README_AR.md">ÿßŸÑÿπÿ±ÿ®Ÿäÿ©</a> |
    <a href="../../README.md">English</a> |
    <a href="README_ES.md">Espa√±ol</a> |
    <a href="README_FR.md">Fran√ßais</a> |
    <a href="README_zh-hans.md">ÁÆÄ‰Ωì‰∏≠Êñá</a>
</p>

<h3 align="center">
    Mod√®les R√©currents Hi√©rarchiques de Pointe pour Mat√©riel √† Faibles Ressources
</h3>

<p align="center">
    THL est un graphe de calcul r√©current hi√©rarchique, strictement non-Transformer, con√ßu pour ex√©cuter de grands mod√®les de langage sur <b>4 Go de VRAM</b> et des appareils mobiles.
</p>

---

**THL** r√©sout le probl√®me sp√©cifique de l'**explosion de la m√©moire cache KV** dans les Transformers en utilisant une **M√©moire Ind√©pendante de la Longueur de S√©quence** (m√©moire O(1) par couche). Il atteint des performances comp√©titives avec les Transformers tout en permettant l'inf√©rence sur du mat√©riel grand public.

## ‚ö° Pourquoi utiliser THL ?

1.  **M√©moire Born√©e (O(1))** : Oubliez le cache KV en O(T). THL utilise une m√©moire √† emplacements fixes (`J=1024`), permettant une g√©n√©ration de contexte infinie sans planter votre GPU.
2.  **R√©currence Hi√©rarchique** : Des niveaux GRU √† √©chelles multiples traitent l'information √† diff√©rentes fr√©quences ($\tau_k$), capturant efficacement la syntaxe locale et la s√©mantique globale.
3.  **Inf√©rence Faible VRAM** : Le **Moteur d'Inf√©rence par Couches** int√©gr√© permet d'ex√©cuter des mod√®les de plus de 7B param√®tres sur <4 Go de VRAM.
4.  **Routage √âpars** : Le routage Top-K multi-t√™tes garantit que les souvenirs pertinents sont consult√©s sans traiter l'historique complet.

## üõ†Ô∏è Installation

```bash
# Cloner le d√©p√¥t
git clone https://github.com/EGen-V/Transformer-Hierarchical-Layers.git
cd Core

# Installer les d√©pendances
pip install -r requirements.txt
pip install .
```

## üöÄ Tour Rapide

### 1. Mod√©lisation de Langue Basique

Instanciez facilement un mod√®le et ex√©cutez une passe avant :

```python
import torch
from thl.config import THLConfig
from thl.model import THLModel

# Configurer pour 4 Go de VRAM
config = THLConfig(
    num_tiers=3,
    memory_slots=1024,
    dim=768
)

model = THLModel(config)
input_ids = torch.randint(0, 50257, (1, 32))
logits, state = model(input_ids)
```

### 2. G√©n√©ration Faible VRAM (Streaming)

Ex√©cutez de plus grands mod√®les en streamant les couches vers le GPU une par une :

```python
from thl.inference.layered import LayeredInferenceEngine
from thl.inference.state import InferenceState

engine = LayeredInferenceEngine(model, device="cuda")
state = InferenceState.init(1, config, model.tiers, model.memory_bank)

# √âtape de g√©n√©ration d'un seul token
token = torch.tensor([123])
logit, state = engine.step(token, state)
```

## üèóÔ∏è Architecture

| Composant | Symbole | Description |
|-----------|---|-------------|
| **Banque de M√©moire** | $M_t$ | Matrice de taille fixe ($J \times d$) conservant le contexte √† long terme. |
| **Routeur √âpars** | $r_t$ | M√©canisme de routage Top-K pour lire les emplacements pertinents. |
| **Niveaux Hi√©rarchiques** | $s_t^{(k)}$ | Pile de cellules r√©currentes mises √† jour √† intervalles exponentiels $\tau=2^k$. |
| **√âcrivain de Nouveaut√©** | $w_t$ | M√©canisme √† porte pour √©crire uniquement les nouvelles informations en m√©moire. |

## üß™ Performance V√©rifi√©e

Nous testons THL rigoureusement. Lancez la suite vous-m√™me :
```bash
./scripts/run_tests.sh
```

## üìú Licence

Ce projet est sous licence MIT.
